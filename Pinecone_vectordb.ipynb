{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWkEX6cBFJ5koihyFwnUG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yosingh1/Machine_Learning/blob/main/Pinecone_vectordb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP8NuorEax1z",
        "outputId": "b5b5a389-a45e-4446-b837-828ae6948945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Collecting pinecone-client==2.2.4\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client==2.2.4)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.10.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client==2.2.4)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2024.2.2)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.6.1 loguru-0.7.2 pinecone-client-2.2.4\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pinecone-client==2.2.4\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj_LyAAta5nP",
        "outputId": "2b82e676-8120-4cfd-d464-f14790de1f20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os"
      ],
      "metadata": {
        "id": "y36R9TR1bO6N"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ubaqzLidkMb",
        "outputId": "c0b3bf92-1170-4416-e2f7-77f4e62e7954"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘pdf’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader=PyPDFDirectoryLoader(\"pdf\")"
      ],
      "metadata": {
        "id": "SIYBVSj9emXv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=loader.load()"
      ],
      "metadata": {
        "id": "VmQuLDR0fygJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_spliter=RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)"
      ],
      "metadata": {
        "id": "Ge99Yq-1f0QV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=text_spliter.split_documents(text)"
      ],
      "metadata": {
        "id": "v7rhge2IgkVr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[100].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aezGbJOIg41W",
        "outputId": "72cea84a-797f-46af-c4d7-4df4b546ae24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base -regressors. Median is more robust to noise than the average.  \n",
            " \n",
            "Another possible way to find wj is to assess the accuracies of the learners (regressor or classifie r) on a \n",
            "separate validation set and use that information to compute the weights, so that we give more weights \n",
            "to more accurate learners.  \n",
            " \n",
            "Voting schemes can be seen as approximations under a Bayesian framework with weights \n",
            "approximating prior model probabi lities, and model decisions approximating model -conditional \n",
            "likelihoods.   \n",
            " \n",
            " \n",
            " \n",
            "Simple voting corresponds to a uniform prior. If we have a prior distribution preferring simpler models, \n",
            "this would give larger weights to them. We cannot integrate over all mode ls; we only choose a subset \n",
            "for which we believe P(Mj ) is high, or we can have another Bayesian step and calculate P(Ci | x,Mj ), the \n",
            "probability of a model given the sample, and sample high probable models from this density.  \n",
            " \n",
            "Let us assume that dj are ii d with expected value E[d j] and variance Var (dj ), then when we take a simple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85VECHb_gmiC",
        "outputId": "297bed86-1062-4276-ce4f-c5421e379c1a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "Embedding_OPEN_AI=userdata.get('Embedding_OPEN_AI')"
      ],
      "metadata": {
        "id": "GGPF-slPgzY-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = Embedding_OPEN_AI"
      ],
      "metadata": {
        "id": "_Gd5iEe4h0Gt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "qARashExh4nh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding.embed_query(\"how are you?\")) #this is dimention size which needs to be defined in pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GRqliUKiI7P",
        "outputId": "3b8b353f-4de0-4983-9ff4-af03c22fbd92"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'aacb5674-79fd-462a-aab8-059487680752')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "COvO_ERfibUm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY, # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV # next to api key in console\n",
        ")\n",
        "index_name=\"test\" # put in the name of your pinecone index here"
      ],
      "metadata": {
        "id": "EfDg48hRjrpm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index= pinecone.Index(\"test\")"
      ],
      "metadata": {
        "id": "cXHpFqiIkGDf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGxESQbZlha8",
        "outputId": "592a58b5-4462-452a-f641-278bc717981b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pinecone.index.Index at 0x781b512eea40>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuRkwehCll6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create embedding for each chunk"
      ],
      "metadata": {
        "id": "oB07O-qvlrgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone"
      ],
      "metadata": {
        "id": "LODF67bBmSmn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to generate embedding from chunks and this vectors will be stored in pinecode vector db\n",
        "docsearch = Pinecone.from_texts([t.page_content for t in text], embedding, index_name=index_name)"
      ],
      "metadata": {
        "id": "IiN93DvilvdS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3veW_vPtmHf6",
        "outputId": "ae1e17fe-2d8e-411a-92db-94c6be541c15"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.pinecone.Pinecone at 0x781b52f933a0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ic4cR14n5_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#similarity search"
      ],
      "metadata": {
        "id": "rp3V_A-ToHb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"machine learing is part of AI?\""
      ],
      "metadata": {
        "id": "DXjZvZbyoJTk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.similarity_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA60CB4qoO_h",
        "outputId": "f8f42d12-a3ff-49a7-c7b2-7976e25e7518"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='1 \\n UNIT I  \\nIntroduction to Machine Learning  \\n1. Introduction  \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain \\nknowledge from data, or both.  \\nArthur Samuel, an early American leader in the field of computer gaming and artificial intellige nce, \\ncoined the term “Machine Learning” in 1959 while at IBM. He defined machine learning as “the field of \\nstudy that gives computers the ability to learn without being explicitly programmed.” However, there is \\nno universally accepted definition for machin e learning. Different authors define the term differently.  \\n \\nDefinition of learning  \\nDefinition  \\nA computer program is said to learn from experience E with respect to some class of tasks T and \\nperformance measure P, if its performance at tasks T, as measured by P, improves with experience E.  \\n \\nExamples  \\ni) Handwriting recognition learning problem  \\n• Task T: Recognising and classifying handwritten words within images  \\n• Performance P: Percent of words correctly classified  \\n• Training experience E: A dataset of handw ritten words with given classifications  \\nii) A robot driving learning problem  \\n• Task T: Driving on highways using vision sensors  \\n• Performance measure P: Average distance traveled before an error  \\n• training  experience: A sequence of images and steering commands recorded while  \\n  observing a human driver  \\niii) A chess learning problem  \\n• Task T: Playing chess  \\n• Performance measure P: Percent of games won against opponents  \\n• Training experience E: Playing practi ce games against itself  \\nDefinition'),\n",
              " Document(page_content='ii) A robot driving learning problem  \\n• Task T: Driving on highways using vision sensors  \\n• Performance measure P: Average distance traveled before an error  \\n• training  experience: A sequence of images and steering commands recorded while  \\n  observing a human driver  \\niii) A chess learning problem  \\n• Task T: Playing chess  \\n• Performance measure P: Percent of games won against opponents  \\n• Training experience E: Playing practi ce games against itself  \\nDefinition  \\nA computer program which learns from experience is called a machine learning program or \\nsimply a learning program. Such a program is sometimes also referred to as a learner.  \\n \\n1.2 Components of Learning  \\n Basic components o f learning process  \\nThe learning process, whether by a human or a machine, can be divided into four components, \\nnamely, data storage, abstraction, generalization and evaluation. Figure 1.1 illustrates the \\nvariouscomponents and the steps involved in the lear ning process.'),\n",
              " Document(page_content='3 \\n 4. In medicine, learning programs are used for medical diagnosis.  \\n5. In telecommunications, call patterns are analyzed for network optimization and maximizing the \\nquality of service.  \\n6. In science, la rge amounts of data in physics, astronomy, and biology can only be analyzed fast \\nenough by computers. The World Wide Web is huge; it is constantly growing and searching for \\nrelevant information cannot be done manually.  \\n7. In artificial intelligence, it is use d to teach a system to learn and adapt to changes so that the \\nsystem designer need not foresee and provide solutions for all possible situations.  \\n8. It is used to find solutions to many problems in vision, speech recognition, and robotics.  \\n9. Machine learning methods are applied in the design of computer -controlled vehicles to steer \\ncorrectly when driving on a variety of roads.  \\n10. Machine learning methods have been used to develop programmes for playing games such as \\nchess, backgammon and Go.  \\n \\n1.3 Learning Models  \\nMachine learning is concerned with using the right features to build the right models that \\nachieve the right tasks.  The basic idea of Learning models has divided into three categories.  \\nFor a given problem, the collection of all possible outcomes represent s the  sample space or instance \\nspace . \\n \\n\\uf0b7 Using a Logical expression. ( Logical models ) \\n\\uf0b7 Using the Geometry of the instance space. ( Geometric models)  \\n\\uf0b7 Using Probability to classify the instance space. ( Probabilistic models ) \\n\\uf0b7 Grouping and Grading  \\n \\n1.3.1  Logical  models  \\nLogical models  use a logical expression to divide the instance space into segments and hence \\nconstruct grouping models. A  logical expression  is an expression that returns a Boolean value, i.e., a \\nTrue or False outcome. Once the data is grouped usin g a logical expression, the data is divided into \\nhomogeneous groupings for the problem we are trying to solve.   For example, for a classiﬁcation'),\n",
              " Document(page_content='TEXT BOOKS:  \\n \\n1. Ethem  Alpaydin, ”Introduction to Machine Learning”, MIT Press, Prentice Hall of India, 3rd \\nEdition2014.  \\n2. Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar ” Foundations of Machine Learning”, MIT \\nPress,2012.  \\n3. Tom Mitchell, “Machine Learning”, McGraw Hill, 3rdEdition, 1997.  \\n4. MACHINE LEARNING - An Algorithmic Perspective, Second Edition , Stephen Marsland , 2015.  \\n \\nREFERENCE BOOKS:  \\n1. CharuC.Aggarwal,“DataClassificationAlgorithmsandApplications”,CRCPress,2014.  \\n2. Charu C. Aggarwal, “DATA CLUSTERING Algorithms and Applications”, CRC Press,  \\n       2014.  \\n3. Kevin P. Murphy ”Machine Learning: A Probabilistic Perspective”, The MIT Press, 2012  \\n4. Jiawei Han and  Micheline Kambers and JianPei, “Data Mining Concepts  \\n      andTechniques”,3rd edition, Morgan Kaufman Publications, 2012.  \\n \\n \\nOUTCOMES:  \\n1. Recognize the characteristics of Machine Learning techniques that enable to solve real world \\nproblems  \\n2. Recognize the char acteristics of machine learning strategies  \\n3. Apply various supervised learning methods to appropriate problems  \\n4. Identify and integrate more than one techniques to enhance the performance of learning  \\n5. Create probabilistic and unsupervised learning mode ls for handling unknown pattern  \\n6. Analyze the co -occurrence of data to find interesting frequent patterns')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm= OpenAI()"
      ],
      "metadata": {
        "id": "mdCr6bifoUv5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "SYpQNbELot8X"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lJ4xwjs2pWxf",
        "outputId": "30735446-8f1e-45a9-ddef-7ac7af890243"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, machine learning is considered a subset or branch of artificial intelligence. It involves teaching computer systems to learn from data and make decisions without being explicitly programmed, using algorithms and models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2=\"can you define deep learning as well\""
      ],
      "metadata": {
        "id": "m0RUIpQHpqCN"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "ltgs2esjp2ar",
        "outputId": "93c77de9-a1fc-438f-a25e-8e74c57a2ece"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Deep learning is a subset of machine learning that uses artificial neural networks to learn from data. It involves training a neural network with multiple hidden layers to extract features and patterns from data, allowing for more complex and accurate predictions or classifications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "  input_user= input(f\"input_prompt: \")\n",
        "  if input_user==\"exit\":\n",
        "    print(\"Exiting\")\n",
        "    sys.exit()\n",
        "  if input_user==\"\":\n",
        "    continue\n",
        "  result= qa({\"query\":input_user})\n",
        "\n",
        "  print(f\"Answer:{result['result']}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "4PMMBQd1p30l",
        "outputId": "8d546aa5-ba12-44c1-9341-d500f33522b7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_prompt: can you define deep learning as well\n",
            "Answer:\n",
            "\n",
            "Deep learning is a subset of machine learning that uses artificial neural networks to learn from large amounts of data. It is inspired by the structure and function of the human brain, with multiple layers of interconnected nodes that process information and learn from it. Deep learning algorithms are able to automatically extract features from data and make highly accurate predictions, making it useful for tasks such as image and speech recognition.\n",
            "input_prompt: exit\n",
            "Exiting\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pj4zk1LRrXk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}